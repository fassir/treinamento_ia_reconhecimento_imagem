{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fassir/treinamento_ia_reconhecimento_imagem/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92mQ2gMlYoZl"
   },
   "source": [
    "# Transferência de aprendizado / ajuste fino\n",
    " \n",
    "Este tutorial irá guiá-lo pelo processo de uso do _transfer learning_ para aprender um classificador de imagens preciso a partir de um número relativamente pequeno de amostras de treinamento. De modo geral, transfer learning refere-se ao processo de aproveitar o conhecimento aprendido em um modelo para o treinamento de outro modelo.\n",
    "\n",
    "Mais especificamente, o processo envolve pegar uma rede neural existente que foi previamente treinada para um bom desempenho em um conjunto de dados maior e usá-la como base para um novo modelo que aproveita a precisão da rede anterior para uma nova tarefa. Esse método se tornou popular nos últimos anos para melhorar o desempenho de uma rede neural treinada em um conjunto de dados pequeno; a intuição é que o novo conjunto de dados pode ser pequeno demais para treinar até um bom desempenho sozinho, mas sabemos que a maioria das redes neurais treinadas para aprender características de imagens geralmente aprende características semelhantes de qualquer maneira, especialmente nas camadas iniciais, onde são mais genéricas (detectores de borda, blobs, etc.).\n",
    " \n",
    "O transfer learning foi amplamente viabilizado pelo código aberto de modelos de ponta; para os modelos de melhor desempenho em tarefas de classificação de imagens (como do [ILSVRC](http://www.image-net.org/challenges/LSVRC/)), é prática comum agora não apenas publicar a arquitetura, mas também liberar os pesos treinados do modelo. Isso permite que amadores usem esses classificadores de imagem de ponta para impulsionar o desempenho de seus próprios modelos específicos de tarefa.\n",
    "\n",
    "#### Extração de características vs. ajuste fino\n",
    " \n",
    "Em um extremo, transfer learning pode envolver pegar a rede pré-treinada e congelar os pesos, usando uma de suas camadas ocultas (geralmente a última) como extrator de características, usando essas características como entrada para uma rede neural menor.\n",
    "\n",
    "No outro extremo, começamos com a rede pré-treinada, mas permitimos que alguns dos pesos (geralmente a última camada ou as últimas camadas) sejam modificados. Outro nome para esse procedimento é \"ajuste fino\" porque estamos ajustando levemente os pesos da rede pré-treinada para a nova tarefa. Normalmente treinamos tal rede com uma taxa de aprendizado menor, já que esperamos que as características já sejam relativamente boas e não precisem ser muito alteradas.\n",
    "\n",
    "Às vezes, fazemos algo intermediário: congelamos apenas as camadas iniciais/genéricas, mas fazemos ajuste fino nas camadas finais. Qual estratégia é melhor depende do tamanho do seu conjunto de dados, do número de classes e de quanto ele se assemelha ao conjunto de dados em que o modelo anterior foi treinado (e, portanto, se pode se beneficiar dos mesmos extratores de características aprendidos). Uma discussão mais detalhada sobre como escolher a estratégia pode ser encontrada em [[1]](http://cs231n.github.io/transfer-learning/) [[2]](http://sebastianruder.com/transfer-learning/).\n",
    " \n",
    "## Procedimento\n",
    " \n",
    "Neste guia, vamos passar pelo processo de carregar um classificador de imagens de ponta com 1000 classes, o [VGG16](https://arxiv.org/pdf/1409.1556.pdf), que [venceu o desafio ImageNet em 2014](http://www.robots.ox.ac.uk/~vgg/research/very_deep/), e usá-lo como extrator de características fixo para treinar um classificador personalizado menor em nossas próprias imagens, embora com poucas alterações no código você também possa tentar o ajuste fino.\n",
    "\n",
    "Primeiro, vamos carregar o VGG16 e remover sua camada final, a camada de classificação softmax de 1000 classes específica do ImageNet, e substituí-la por uma nova camada de classificação para as classes que estamos treinando. Em seguida, vamos congelar todos os pesos da rede, exceto os novos que conectam à nova camada de classificação, e então treinar a nova camada de classificação em nosso novo conjunto de dados.\n",
    "\n",
    "Também vamos comparar esse método com o treinamento de uma pequena rede neural do zero no novo conjunto de dados e, como veremos, isso irá melhorar drasticamente nossa precisão. Faremos essa parte primeiro.\n",
    "\n",
    "Como nosso exemplo, usaremos o conjunto de dados **Microsoft Cats and Dogs** com cerca de 25.000 imagens pertencentes a **2 categorias**: Cat e Dog. Treinaremos um classificador de imagens para distinguir entre essas duas classes. Vale notar que essa estratégia escala bem para conjuntos de imagens onde você pode ter até algumas centenas ou menos de imagens. O desempenho será menor com um número pequeno de amostras (dependendo das classes), como de costume, mas ainda assim impressionante considerando as restrições usuais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3p-OjhDPYoZm",
    "outputId": "8240657a-5982-4f20-c272-8f830adae8b2"
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "#se estiver usando Theano com GPU\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWWN-FPLYoZs"
   },
   "source": [
    "### Obtendo um conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "XklKIrnaZb3f",
    "outputId": "85c8a89c-e882-4e54-c7cf-1466fca5f8d4"
   },
   "outputs": [],
   "source": [
    "!echo \"Baixando kagglecatsanddogs_5340.zip para o notebook\"\n",
    "!curl -L -o kagglecatsanddogs_5340.zip --progress-bar https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
    "!unzip -q kagglecatsanddogs_5340.zip\n",
    "!ls kagglecatsanddogs_5340/PetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "8OGRcLNwYoZu",
    "outputId": "c5195ab1-d738-40da-dc08-f147efd43f4e"
   },
   "outputs": [],
   "source": [
    "root = 'kagglecatsanddogs_5340/PetImages'\n",
    "categories = [os.path.join(root, c) for c in os.listdir(root) if os.path.isdir(os.path.join(root, c))]\n",
    "print(categories)\n",
    "train_split, val_split = 0.7, 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2ERhVlFYoZy"
   },
   "source": [
    "Esta função é útil para pré-processar os dados em uma imagem e vetor de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1T1Joq7YoZz"
   },
   "outputs": [],
   "source": [
    "# função auxiliar para carregar imagem e retornar a imagem e o vetor de entrada\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUwQ60GGYoZ3"
   },
   "source": [
    "Carregue todas as imagens da pasta raiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nAUr-ooYoZ4"
   },
   "outputs": [],
   "source": [
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames\n",
    "              in os.walk(category) for f in filenames\n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        try:\n",
    "            img, x = get_image(img_path)\n",
    "            data.append({'x': np.array(x[0]), 'y': c})\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            # Arquivo ignorado: não pôde ser aberto como imagem\n",
    "            continue\n",
    "\n",
    "# contar o número de classes\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55Rw-ptVYoZ7"
   },
   "source": [
    "Aleatorize a ordem dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vGeJK55YoZ8"
   },
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwHqS_NgYoZ_"
   },
   "source": [
    "criar divisão de treino / validação / teste (70%, 15%, 15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT9Cuq2rYoaB"
   },
   "outputs": [],
   "source": [
    "idx_val = int(train_split * len(data))\n",
    "idx_test = int((train_split + val_split) * len(data))\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsOVhpqcYoaF"
   },
   "source": [
    "Separe os dados dos rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "vQOGN9kOYoaH",
    "outputId": "b992f7bd-aca6-4d4d-e79d-9efaeeb7d2be"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
    "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
    "print(\"Primeiros 5 itens de y_test:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc6W07QVYoaM"
   },
   "source": [
    "Pré-processe os dados como antes, garantindo que estejam em float32 e normalizados entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qnXaiAgJYoaQ",
    "outputId": "4f20cdc6-c6a4-4f88-e45f-e7fbedfcdc55"
   },
   "outputs": [],
   "source": [
    "# normalizar os dados\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# converter rótulos para vetores one-hot\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ordUucUKYoaS"
   },
   "source": [
    "Vamos obter um resumo do que temos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "AcKjxgtyYoaT",
    "outputId": "7b8456a1-472b-45ce-818f-3b0f670aac94"
   },
   "outputs": [],
   "source": [
    "# resumo\n",
    "print(\"carregamento finalizado de %d imagens de %d categorias\"%(len(data), num_classes))\n",
    "print(\"divisão treino / validação / teste: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
    "print(\"formato dos dados de treino: \", x_train.shape)\n",
    "print(\"formato dos rótulos de treino: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-P9MNPcYoaY"
   },
   "source": [
    "Se tudo funcionou corretamente, você deve ter carregado as imagens do dataset **Microsoft Cats and Dogs** e as dividido em três conjuntos: `train` (treino), `val` (validação) e `test` (teste).\n",
    " \n",
    "O formato dos dados de treino será (`n`, 224, 224, 3), onde `n` é o número de imagens no conjunto de treino, 224x224 é o tamanho das imagens e 3 representa os canais de cor (RGB). Os rótulos estarão no formato (`n`, 2), pois temos **2 classes**: Cat e Dog.\n",
    " \n",
    "A divisão dos dados foi feita para garantir uma avaliação correta do classificador:\n",
    "- `train`: usado para treinar o modelo\n",
    "- `val`: usado para validação durante o treinamento (ajuste de hiperparâmetros e prevenção de overfitting)\n",
    "- `test`: usado apenas ao final, para avaliar a acurácia final do modelo em dados nunca vistos\n",
    " \n",
    "Vamos rapidamente visualizar algumas imagens de exemplo do nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "y84SmM2CYoaZ",
    "outputId": "37c0137b-d993-4b2d-fa4b-51fe368e8fa1"
   },
   "outputs": [],
   "source": [
    "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "idx = [int(len(images) * random.random()) for i in range(8)]\n",
    "imgs = [image.load_img(images[i], target_size=(224, 224)) for i in idx]\n",
    "concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(concat_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2s5qypkYoad"
   },
   "source": [
    "### Primeiro, treinando uma rede neural do zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "y41GiiYTYoaf",
    "outputId": "02570f8a-c565-4aee-e299-5af6f464377d"
   },
   "outputs": [],
   "source": [
    "# construir a rede\n",
    "model = Sequential()\n",
    "print(\"Input dimensions: \",x_train.shape[1:])\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej9IWCzxYoai"
   },
   "source": [
    "Criamos uma rede de tamanho médio com cerca de 1,2 milhão de pesos e vieses (os parâmetros). A maioria deles está levando para a camada totalmente conectada pré-softmax \"dense_5\".\n",
    " \n",
    "Agora podemos treinar nosso modelo por 10 épocas com um batch size de 128. Também registraremos seu histórico para podermos plotar a perda ao longo do tempo depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "CIqHecNAYoaj",
    "outputId": "6456ff7a-34b7-4d23-ac2f-742b2dbdece4"
   },
   "outputs": [],
   "source": [
    "# compilar o modelo para usar função de perda entropia cruzada categórica e otimizador adadelta\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG0CKOI1Yoao"
   },
   "source": [
    "Vamos plotar a perda de validação e a acurácia de validação ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "_CCPq_ndYoap",
    "outputId": "99227211-9f16-4e5f-ceaa-68beb3817ad4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history.history[\"val_loss\"])\n",
    "ax.set_title(\"perda de validação\")\n",
    "ax.set_xlabel(\"épocas\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(history.history[\"val_acc\"])\n",
    "ax2.set_title(\"acurácia de validação\")\n",
    "ax2.set_xlabel(\"épocas\")\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI7Mj6-RYoau"
   },
   "source": [
    "Observe que a perda de validação começa a aumentar após cerca de 16 épocas, mesmo que a acurácia de validação permaneça aproximadamente entre 40% e 50%. Isso sugere que nosso modelo começa a sobreajustar por volta desse ponto, e o melhor desempenho teria sido alcançado se tivéssemos parado antes. No entanto, nossa acurácia provavelmente não teria passado de 50%, e provavelmente seria menor.\n",
    " \n",
    "Também podemos obter uma avaliação final rodando nosso modelo no conjunto de teste. Fazendo isso, obtemos os seguintes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "8Itd5LDAYoav",
    "outputId": "97d9a1ed-e135-4b08-ca1c-9053758db9b1"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Perda no teste:', loss)\n",
    "print('Acurácia no teste:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIwMY_ZXYoax"
   },
   "source": [
    "## Transferência de aprendizado começando com uma rede existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "KpUDAbxiYoay",
    "outputId": "ed9ec74b-6697-438b-8e82-61df8c9da39f"
   },
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLXTofcNYoa2"
   },
   "source": [
    "Observe que o VGG16 é _muito_ maior do que a rede que construímos anteriormente. Ele contém 13 camadas convolucionais e duas camadas totalmente conectadas no final, e possui mais de 138 milhões de parâmetros, cerca de 100 vezes mais do que a rede que fizemos acima. Como nossa primeira rede, a maioria dos parâmetros está nas conexões que levam à primeira camada totalmente conectada.\n",
    " \n",
    "O VGG16 foi feito para resolver o ImageNet e atinge um [erro top-5 de 8,8%](https://github.com/jcjohnson/cnn-benchmarks), o que significa que 91,2% das amostras de teste foram classificadas corretamente entre as 5 melhores previsões para cada imagem. Sua acurácia top-1 -- equivalente à métrica de acurácia que usamos (a previsão principal está correta) -- é de 73%. Isso é especialmente impressionante, já que não são apenas 97, mas 1000 classes, o que significa que chutes aleatórios nos dariam apenas 0,1% de acurácia.\n",
    " \n",
    "Para usar essa rede em nossa tarefa, \"removemos\" a camada final de classificação, a camada softmax de 1000 neurônios no final, que corresponde ao ImageNet, e a substituímos por uma nova camada softmax para nosso conjunto de dados, que contém 97 neurônios no caso do conjunto 101_ObjectCategories.\n",
    " \n",
    "Em termos de implementação, é mais fácil simplesmente criar uma cópia do VGG da camada de entrada até a penúltima camada e trabalhar com isso, em vez de modificar o objeto VGG diretamente. Então, tecnicamente, nunca \"removemos\" nada, apenas contornamos/ignoramos. Isso pode ser feito da seguinte forma, usando a classe `Model` do keras para inicializar um novo modelo cuja camada de entrada é a mesma do VGG, mas cuja camada de saída é nossa nova camada softmax, chamada `new_classification_layer`. Observação: embora pareça que estamos duplicando essa grande rede, internamente o Keras está apenas copiando todas as camadas por referência, então não precisamos nos preocupar com sobrecarga de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFL-fLitYoa3"
   },
   "outputs": [],
   "source": [
    "# criar uma referência para a camada de entrada do VGG\n",
    "inp = vgg.input\n",
    "\n",
    "# criar uma nova camada softmax com num_classes neurônios\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "# conectar nossa nova camada à penúltima camada do VGG e fazer referência a ela\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "# criar uma nova rede entre inp e out\n",
    "model_new = Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBIp3fbQYoa9"
   },
   "source": [
    "Vamos re-treinar essa rede, `model_new`, no novo conjunto de dados e rótulos. Mas primeiro, precisamos congelar os pesos e vieses em todas as camadas da rede, exceto a nova no final, com a expectativa de que as características aprendidas no VGG ainda sejam bastante relevantes para a nova tarefa de classificação de imagens. Não é o ideal, mas provavelmente melhor do que conseguimos treinar com nosso conjunto de dados limitado.\n",
    " \n",
    "Ao definir o parâmetro `trainable` como falso em cada camada (exceto nossa nova camada de classificação), garantimos que todos os pesos e vieses dessas camadas permaneçam fixos, e treinamos apenas os pesos da camada final. Em alguns casos, pode ser interessante *não* congelar todas as camadas pré-classificação. Se seu conjunto de dados tiver amostras suficientes e não se parecer muito com o ImageNet, pode ser vantajoso fazer ajuste fino em algumas camadas do VGG junto com o novo classificador, ou até mesmo em todas. Para isso, basta alterar o código abaixo para tornar mais camadas treináveis.\n",
    " \n",
    "No caso do CalTech-101, vamos apenas fazer extração de características, temendo que o ajuste fino em excesso com esse conjunto de dados cause overfitting. Mas talvez estejamos errados? Um bom exercício seria testar ambos e comparar os resultados.\n",
    " \n",
    "Portanto, vamos congelar as camadas e compilar o novo modelo com exatamente o mesmo otimizador e função de perda do nosso primeiro modelo, para uma comparação justa. Em seguida, rodamos `summary` novamente para ver a arquitetura da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "e_n5A8oGYoa9",
    "outputId": "ebe81af3-f953-4351-ef10-5b63f3d19d75"
   },
   "outputs": [],
   "source": [
    "# tornar todas as camadas não treináveis congelando os pesos (exceto a última camada)\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# garantir que a última camada seja treinável/não congelada\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B9G0gC1YobD"
   },
   "source": [
    "Olhando o resumo, vemos que a rede é idêntica ao modelo VGG que instanciamos anteriormente, exceto pela última camada, que antes era um softmax de 1000 neurônios e agora foi substituída por um novo softmax de 97 neurônios. Além disso, ainda temos cerca de 134 milhões de pesos, mas agora a grande maioria deles são \"parâmetros não treináveis\" porque congelamos as camadas em que estão contidos. Agora temos apenas 397.000 parâmetros treináveis, o que é apenas um quarto do número de parâmetros necessários para treinar o primeiro modelo.\n",
    " \n",
    "Como antes, vamos treinar o novo modelo, usando os mesmos hiperparâmetros (tamanho do batch e número de épocas) de antes, junto com o mesmo algoritmo de otimização. Também acompanhamos seu histórico durante o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "aDdq71XNYobD",
    "outputId": "907479a2-3a12-44b7-b706-3f86e3a4ea26"
   },
   "outputs": [],
   "source": [
    "history2 = model_new.fit(x_train, y_train,\n",
    "                         batch_size=128,\n",
    "                         epochs=10,\n",
    "                         validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPqJ0OM8YobI"
   },
   "source": [
    "Nossa acurácia de validação fica próxima de 80% ao final, o que é mais de 30% de melhoria em relação à rede original treinada do zero (ou seja, erramos 20% das amostras, em vez de 50%).\n",
    " \n",
    "Vale notar também que essa rede treina _um pouco mais rápido_ do que a rede original, apesar de ter mais de 100 vezes mais parâmetros! Isso ocorre porque congelar os pesos elimina a necessidade de fazer backpropagation em todas essas camadas, economizando tempo de execução.\n",
    " \n",
    "Vamos plotar novamente a perda e a acurácia de validação, agora comparando o modelo original treinado do zero (em azul) e o novo modelo com transferência de aprendizado (em verde)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "SHLdHnuuYobJ",
    "outputId": "bd5a066f-c94c-4ac4-adc5-3154e6143a29"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history.history[\"val_loss\"])\n",
    "ax.plot(history2.history[\"val_loss\"])\n",
    "ax.set_title(\"perda de validação\")\n",
    "ax.set_xlabel(\"épocas\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(history.history[\"val_acc\"])\n",
    "ax2.plot(history2.history[\"val_acc\"])\n",
    "ax2.set_title(\"acurácia de validação\")\n",
    "ax2.set_xlabel(\"épocas\")\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXjfVTVIYobM"
   },
   "source": [
    "Observe que, enquanto o modelo original começou a sobreajustar por volta da época 16, o novo modelo continuou a diminuir lentamente sua perda ao longo do tempo, e provavelmente teria melhorado um pouco mais sua acurácia com mais iterações. O novo modelo chegou a cerca de 80% de acurácia top-1 (no conjunto de validação) e continuou melhorando lentamente até 100 épocas.\n",
    " \n",
    "Talvez pudéssemos ter melhorado o modelo original com mais regularização ou mais dropout, mas dificilmente alcançaríamos o ganho de >30% em acurácia.\n",
    " \n",
    "Novamente, fazemos uma validação final no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "zMxC6Pd1YobN",
    "outputId": "944eede7-79a7-42b3-ba26-bd883c2e7b46"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Perda no teste:', loss)\n",
    "print('Acurácia no teste:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iUykardYobR"
   },
   "source": [
    "Para prever uma nova imagem, basta rodar o código a seguir para obter as probabilidades de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YpRcsywEYobT",
    "outputId": "858eb7b8-f403-451c-83b9-7eda70671cfc"
   },
   "outputs": [],
   "source": [
    "img, x = get_image('kagglecatsanddogs_5340/PetImages/Cat/7.jpg')\n",
    "probabilities = model_new.predict([x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2ahKv8XYobY"
   },
   "source": [
    "### Melhorando os resultados"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
